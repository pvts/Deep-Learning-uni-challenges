{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group 24--- Machine Learning Course, Tilburg University, Block II/2019-2020\n",
    "#ML Speech Classification Challenge\n",
    "\n",
    "#Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, BatchNormalization, MaxPooling1D, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data\n",
    "b = np.load('feat.npy', allow_pickle = True)\n",
    "path = np.load('path.npy', allow_pickle = True)\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import MFCC files and merge with train data\n",
    "df_npy = pd.DataFrame()\n",
    "df_npy['Mel Freq'] = b\n",
    "df_npy['Audiofile'] = path\n",
    "\n",
    "train = train.rename(columns={\"path\": \"Audiofile\", \"word\": \"Target\"})\n",
    "df_train = df_npy.merge(train, on=\"Audiofile\", how = 'inner')\n",
    "mel = df_train[\"Mel Freq\"]\n",
    "mel_np = np.array(mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty array for padding the features\n",
    "newarray = np.zeros([94824,99,13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, y in enumerate(mel_np):\n",
    "    for i, u in enumerate(y):\n",
    "        for j, o in enumerate(u):\n",
    "            newarray[index][i][j] = o\n",
    "            \n",
    "mel_freq = newarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target labels\n",
    "targets = []\n",
    "target = df_train[\"Target\"]\n",
    "for t in target:\n",
    "    targets.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into a train and test set\n",
    "X = mel_freq\n",
    "y = targets \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot Indicator array for classes\n",
    "onehot = LabelBinarizer()\n",
    "Y_train = onehot.fit_transform(y_train)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded_y_val = label_encoder.fit_transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the labels\n",
    "y_val = to_categorical(integer_encoded_y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Early Stopping to reduce overfitting\n",
    "checkpoint = ModelCheckpoint(filepath = 'bestmodel.hdf5', mode='auto', save_best_only=True,\n",
    "                             restore_best_weights=True, verbose=1)\n",
    "Early_Stopping = EarlyStopping(monitor='val_accuracy', patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining callbacks and our validation set\n",
    "callbacks = [Early_Stopping, checkpoint]\n",
    "validation= [X_val, y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "input_shape = X_train[0].shape #99, 13\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters = 128, kernel_size = 8, activation='relu', input_shape = input_shape))\n",
    "model.add(MaxPooling1D(13))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(435, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(335))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(235))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(135))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(35, activation='softmax'))\n",
    "\n",
    "#optimizer = Adam(lr=0.003)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics = ['accuracy'])\n",
    "final_model = model.fit(X_train, Y_train, epochs=150, batch_size=60, verbose=1, \n",
    "                        validation_data=validation,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"bestmodel.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcuting accuracy and loss\n",
    "score = model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "print('Validation loss:',score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_val,verbose = False)\n",
    "y_pred = to_categorical(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating 1D arrays to plot\n",
    "y_val_plt = y_val.argmax(axis=1)\n",
    "y_pred_plt = y_pred.argmax(axis=1)\n",
    "\n",
    "#Visualize the expected vs the predicted output\n",
    "output = pd.DataFrame()\n",
    "output['Expected Output'] = y_val_plt\n",
    "output['Predicted Output'] = y_pred_plt\n",
    "#output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting train vs validation accuracy\n",
    "history = final_model \n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting train vs validation loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating precision\n",
    "print(precision_score(y_val, y_pred, average = 'macro'))\n",
    "\n",
    "#Calculating recall\n",
    "print(recall_score(y_val, y_pred, average = 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the test set with MFCC files\n",
    "test = test.rename(columns={\"path\": \"Audiofile\"})\n",
    "df_test = test.merge(df_npy, on=\"Audiofile\", how = 'inner')\n",
    "mel_test = df_test[\"Mel Freq\"]\n",
    "mel_np_test = np.array(mel_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zero array for padding for the test set\n",
    "newarray = np.zeros([11005,99,13])\n",
    "\n",
    "for index, y in enumerate(mel_np_test):\n",
    "    for i, u in enumerate(y):\n",
    "        for j, o in enumerate(u):\n",
    "            newarray[index][i][j] = o\n",
    "            \n",
    "test_array = newarray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the model the make predictions on the test set\n",
    "y_test = model.predict_classes(test_array)\n",
    "results = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "final = pd.DataFrame()\n",
    "final[\"path\"] = df_test[\"Audiofile\"]\n",
    "final[\"word\"] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the final results.csv file\n",
    "final.to_csv('result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
